{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "T-R4Td-U8auO"
   },
   "source": [
    "# Building a concepts co-occurence network\n",
    "\n",
    "This Python notebook shows how to use the [Dimensions Analytics API](https://www.dimensions.ai/dimensions-apis/) in order to extract [concepts](https://docs.dimensions.ai/dsl/language.html#searching-using-concepts) from publications and use them to generate a 'topics map' using co-occurence information. For more background on concepts, see also the [Working with concepts in the Dimensions API](https://api-lab.dimensions.ai/cookbooks/1-getting-started/7-Working-with-concepts.html) tutorial.\n",
    "\n",
    "**Note** this tutorial is best experienced using Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==\n",
      "CHANGELOG\n",
      "This notebook was last run on Jan 24, 2022\n",
      "==\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"==\\nCHANGELOG\\nThis notebook was last run on %s\\n==\" % datetime.date.today().strftime('%b %d, %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "hMaQlB7DG8Vw"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook assumes you have installed the [Dimcli](https://pypi.org/project/dimcli/) library and are familiar with the *Getting Started* tutorial. The [networkx](https://networkx.github.io/documentation/stable/reference/introduction.html) and [pyvis](https://pyvis.readthedocs.io/en/latest/tutorial.html) libraries are used for generating and visualizing the network, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25240,
     "status": "ok",
     "timestamp": 1594223315965,
     "user": {
      "displayName": "Michele Pasin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiYfmLTPbeMuYDDrETLbTVXTXnfVr9f7eBtkmR73A=s64",
      "userId": "10309320684375994511"
     },
     "user_tz": -60
    },
    "id": "DLvU1a94tsyL",
    "outputId": "28c39e72-ae52-41c7-8cdd-374b5bfac11f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mSearching config file credentials for 'https://app.dimensions.ai' endpoint..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==\n",
      "Logging in..\n",
      "\u001b[2mDimcli - Dimensions API Client (v0.9.6)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.0\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dimcli plotly networkx pyvis jsonpickle  -U --quiet\n",
    "\n",
    "import dimcli\n",
    "from dimcli.utils import *\n",
    "from dimcli.utils.networkviz import NetworkViz # custom version of pyvis - colab-compatible\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "\n",
    "print(\"==\\nLogging in..\")\n",
    "# https://digital-science.github.io/dimcli/getting-started.html#authentication\n",
    "ENDPOINT = \"https://app.dimensions.ai\"\n",
    "if 'google.colab' in sys.modules:\n",
    "  import getpass\n",
    "  KEY = getpass.getpass(prompt='API Key: ')  \n",
    "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "else:\n",
    "  KEY = \"\"\n",
    "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cBrlkPX5HMY6"
   },
   "source": [
    "## Step 1: Creating a dataset \n",
    "\n",
    "We start by creating a dataset consisting of the most cited 1000 publications matching a chosen keyword. \n",
    "\n",
    "The API query below will return a list of documents including all the related concepts. \n",
    "\n",
    "Tip: try changing the query keyword in order to experiment with different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "iMMJGVQEt8ob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned Publications: 1000 (total = 166253)\n",
      "\u001b[2mTime: 3.55s\u001b[0m\n",
      "Total concepts: 50150\n",
      "Concepts score average 0.3988755936191426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>concepts_count</th>\n",
       "      <th>concept</th>\n",
       "      <th>score</th>\n",
       "      <th>frequency</th>\n",
       "      <th>score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pub.1056527616</td>\n",
       "      <td>The Semantic Web</td>\n",
       "      <td>2</td>\n",
       "      <td>Web</td>\n",
       "      <td>0.069</td>\n",
       "      <td>159</td>\n",
       "      <td>0.46508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pub.1056527616</td>\n",
       "      <td>The Semantic Web</td>\n",
       "      <td>2</td>\n",
       "      <td>Semantic Web</td>\n",
       "      <td>0.006</td>\n",
       "      <td>81</td>\n",
       "      <td>0.65509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pub.1010449058</td>\n",
       "      <td>Social Network Sites: Definition, History, and...</td>\n",
       "      <td>31</td>\n",
       "      <td>special theme section</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pub.1010449058</td>\n",
       "      <td>Social Network Sites: Definition, History, and...</td>\n",
       "      <td>31</td>\n",
       "      <td>scholarship</td>\n",
       "      <td>0.262</td>\n",
       "      <td>2</td>\n",
       "      <td>0.43800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pub.1010449058</td>\n",
       "      <td>Social Network Sites: Definition, History, and...</td>\n",
       "      <td>31</td>\n",
       "      <td>theme section</td>\n",
       "      <td>0.261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "0  pub.1056527616                                   The Semantic Web   \n",
       "1  pub.1056527616                                   The Semantic Web   \n",
       "2  pub.1010449058  Social Network Sites: Definition, History, and...   \n",
       "3  pub.1010449058  Social Network Sites: Definition, History, and...   \n",
       "4  pub.1010449058  Social Network Sites: Definition, History, and...   \n",
       "\n",
       "   concepts_count                concept  score  frequency  score_avg  \n",
       "0               2                    Web  0.069        159    0.46508  \n",
       "1               2           Semantic Web  0.006         81    0.65509  \n",
       "2              31  special theme section  0.283          1    0.28300  \n",
       "3              31            scholarship  0.262          2    0.43800  \n",
       "4              31          theme section  0.261          1    0.26100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@markdown Enter the keyword used to seed the search\n",
    "KEYWORD = \"Semantic Web\" #@param {type:\"string\"}\n",
    "\n",
    "q = f\"\"\"search publications \n",
    "            for \"\\\\\"{KEYWORD}\\\\\"\" \n",
    "        return publications[id+title+concepts_scores] \n",
    "        sort by times_cited limit 1000\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "data = dsl.query(q)\n",
    "concepts = data.as_dataframe_concepts()\n",
    "print(\"Total concepts:\", len(concepts))\n",
    "print(\"Concepts score average\", concepts['score_avg'].mean())\n",
    "concepts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "0SRjG7AE8auX"
   },
   "source": [
    "## Step 2: Building a concepts co-occurrence network\n",
    "\n",
    "Each publication in our dataset includes a list of related concepts. In order to build a concepts co-occurrence network, we simply add an edge between concepts that appear in the same document. \n",
    "\n",
    "Edges have a default weight of 1. If any two concepts appear together in more documents, we increase the weight each time. \n",
    "\n",
    "Note: the resulting network can be very large, so in order to make our network smaller (and more relevant), we can filter out less interesting concepts in two ways:\n",
    "\n",
    "* by setting a `frequency` and `score_avg` threshold (as shown in the [Working with concepts in the Dimensions API](https://api-lab.dimensions.ai/cookbooks/1-getting-started/7-Working-with-concepts.html) tutorial)\n",
    "* by keeping only nodes that, in our network, have an edge > MIN WEIGHT (that is, nodes that have more connections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "hQP7yyd28auZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 239 Edges: 0\n",
      ".. adding edges from pubs cooccurrence...\n",
      "Nodes: 239 Edges: 2115\n",
      ".. cleaning up edges with weight < 2...\n",
      "Nodes: 239 Edges: 490\n",
      ".. removing isolated nodes...\n",
      "Nodes: 201 Edges: 490\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph() # networkX instance\n",
    "\n",
    "#\n",
    "# TIP play with these parameters in ordeto generate different types of networks\n",
    "#\n",
    "MIN_CONCEPT_SCORE = 0.6\n",
    "MIN_CONCEPT_FREQUENCY = 4\n",
    "MIN_EDGE_WEIGHT = 2\n",
    "\n",
    "CONCEPTS_SET = concepts.query(f\"score_avg >= {MIN_CONCEPT_SCORE} & frequency >=  {MIN_CONCEPT_FREQUENCY}\")\n",
    "\n",
    "\n",
    "#\n",
    "# build nodes from concepts, including score_avg and frequency\n",
    "# -- NOTE: score_bucket indicates if the concepts is above or below the mean_score\n",
    "# -- this value is used in the visualization below to color-code nodes\n",
    "#\n",
    "mean_score = CONCEPTS_SET['score_avg'].mean()\n",
    "for index, row in CONCEPTS_SET.drop_duplicates(\"concept\").iterrows():\n",
    "    score_bucket = 1 if row['score_avg'] > mean_score else 2\n",
    "    G.add_node(row['concept'],frequency=row['frequency'], score_avg=row['score_avg'], score_bucket=score_bucket)\n",
    "print(\"Nodes:\", len(G.nodes()), \"Edges:\", len(G.edges()))\n",
    "\n",
    "#\n",
    "# build edges, based on concepts co-occurrence within pubs\n",
    "# -- calculate a 'weight' based on how often two concepts co-occur\n",
    "#\n",
    "print(f\".. adding edges from pubs cooccurrence...\")\n",
    "pubs_list = CONCEPTS_SET.drop_duplicates(\"id\")['id'].to_list()\n",
    "\n",
    "for p in pubs_list:\n",
    "    concepts_for_this_pub = CONCEPTS_SET[CONCEPTS_SET['id'] == p]['concept'].to_list()\n",
    "    for group in itertools.combinations(concepts_for_this_pub, 2):  # gen all permutations\n",
    "        a, b = group[0], group[1]\n",
    "        try:\n",
    "            G.edges[a, b]['weight'] = G.edges[a, b]['weight'] + 1 \n",
    "        except:\n",
    "            G.add_edge(a, b, weight=1)\n",
    "            \n",
    "print(\"Nodes:\", len(G.nodes()), \"Edges:\", len(G.edges()))\n",
    "\n",
    "#\n",
    "# this extra step is useful to remove low-weight connections\n",
    "#\n",
    "\n",
    "print(f\".. cleaning up edges with weight < {MIN_EDGE_WEIGHT}...\")\n",
    "\n",
    "for a, b, w in list(G.edges(data='weight')):\n",
    "    if w < MIN_EDGE_WEIGHT:\n",
    "        G.remove_edge(a, b)\n",
    "print(\"Nodes:\", len(G.nodes()), \"Edges:\", len(G.edges()))\n",
    "\n",
    "print(f\".. removing isolated nodes...\")\n",
    "\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print(\"Nodes:\", len(G.nodes()), \"Edges:\", len(G.edges()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "X7JMkbPy8aub"
   },
   "source": [
    "## Step 3: Visualizing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "mSxz5bqY8auc"
   },
   "source": [
    "Note \n",
    "\n",
    "* We're using a custom version of [pyvis](https://pyvis.readthedocs.io/en/latest/tutorial.html) which is included in [dimcli.core.extras](https://github.com/digital-science/dimcli/blob/master/dimcli/core/extras.py) and is called `NetworkViz`. This custom version fixes a bug that prevents pyvis graphs to be displayed in Google Colab.\n",
    "* The pyvis `from_nx` method doesn't carry through WEIGHT or any other value from our network data; so we need to set it manually using via another pass \n",
    "* using `score_bucket` (see above), we can mark the higher-score concepts using a brighter color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Sy5TRJ454qi6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"concepts_network.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x14cfc9220>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viznet = NetworkViz(notebook=True, width=\"100%\", height=\"800px\")\n",
    "viznet.toggle_hide_edges_on_drag(True)\n",
    "viznet.barnes_hut()\n",
    "viznet.repulsion(300)\n",
    "viznet.heading = f\"Concepts co-occurrence for '{KEYWORD}' publications\"\n",
    "\n",
    "\n",
    "# reuse plotly color palette\n",
    "palette = px.colors.diverging.Temps  # 7 colors\n",
    "\n",
    "viznet.from_nx(G)\n",
    "\n",
    "\n",
    "# update visual features \n",
    "\n",
    "for node in viznet.nodes:\n",
    "    freq = G.nodes[node['label']]['frequency']\n",
    "    score_avg = G.nodes[node['label']]['score_avg']\n",
    "    score_bucket = G.nodes[node['label']]['score_bucket'] # get from original network\n",
    "\n",
    "    node['size'] = freq * 2\n",
    "    node['color'] = palette[3*score_bucket]  # get color based on score_bucket (1 or 2)\n",
    "    node['borderWidthSelected'] = 5\n",
    "    node['title'] = f\"<h4>Concept: '{node['label']}'</h4><hr>Frequency: {freq}<br>Score avg: {score_avg}\",\n",
    "    # print(node)\n",
    "for edge in viznet.edges:\n",
    "    # get value from main Network weight\n",
    "    edge['value'] = G.edges[edge['from'], edge['to']]['weight']\n",
    "    # print(edge)\n",
    "    \n",
    "viznet.show(\"concepts_network.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "In this tutorial we have demonstrated how to generate an concepts 'co-occurence network diagram' using the Dimensions API. \n",
    "\n",
    "The resulting visualization is also [available as a standalone file here](http://api-sample-data.dimensions.ai/dataviz-exports/concets-cooccurence/concepts_network_2020-08-05.html).\n",
    "\n",
    "For more information on this topic, see also the [official documentation on concepts](https://docs.dimensions.ai/dsl/language.html#searching-using-concepts) and the [Working with concepts in the Dimensions API](https://api-lab.dimensions.ai/cookbooks/1-getting-started/7-Working-with-concepts.html) tutorial."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NetworkX-concepts-v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
